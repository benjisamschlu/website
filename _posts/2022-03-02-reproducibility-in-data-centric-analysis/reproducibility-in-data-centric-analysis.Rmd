---
title: "Reproducibility in data-centric analyses"
description: |
  Highlighting good practices for reproducibility.
base_url: https://www.benjaminschluter.com
author:
  - name: Benjamin Schl√ºter
date: 02-10-2022
output:
  distill::distill_article:
    self_contained: false
    highlight: monochrome
preview: reproVSrepli.jpg
---

```{r, echo = FALSE}
knitr::opts_chunk$set()
library("here")
```


In this post, I will summarize a talk I made to the members of my research center ([DEMO](https://uclouvain.be/en/research-institutes/iacchos/demo)), promoting reproducibility. I focused on **computation reproducibility** which requires that someone else should be able to reproduce your results with the materials (data, codes, guidance) you provided. This transparency is necessary as our research results are used to inform public and health policies. The key elements I will go through should be seen as minimal requirements for reproducibility. I am sharing my own practice but there are of course other (better) ways to do.

```{r, echo = FALSE, fig.cap="Figure from radiance.org.uk", out.width=400, out.height=300, fig.align = "center"}
knitr::include_graphics(path = "./figures/reproVSrepli.JPG")
```


# Folder's structure

For someone else to be able to reproduce your analysis, a first requirement is that the repository associated to a research project is well organized. In addition, the project's folder structure must allow an evolution over a long period of time (sometimes really long...). Hence, your desktop should definitely not look like this one (no judgment here):


```{r, echo = FALSE, fig.cap="The don't...", out.width=400, out.height=300, fig.align = "center"}
knitr::include_graphics(path = "./figures/messy_files.jpg")
```

My actual practice is to structure my project folder, here named "*5-15 mortality estimation*", as follows

```{r, echo = FALSE, fig.cap="...and the do", out.width=400, out.height=300, fig.align = "center"}
knitr::include_graphics(path = "./figures/clean_files.png")
```

This structure allows the project to evolve from data cleaning to submission, while maintaining a constant structure. At minimum, `code` has a subfolder called `function`, where I store R functions created for the project. I also add a `stan` subfolder for my Stan scripts. Each R code has a specific aim, for example, there will be one R code for data cleaning, one for exploratory data analysis (EDA) and so on. In the `product` folder, I usually store reports on EDA and manuscript drafts. I also write a mardown file for the project history. Note also that I locate my R project associated to that reseach project in the folder (bottom of the screen shot). It makes it easy to load data and functions, store data etc.


# Project history

In order to be transparent about the research process, I try to maintain a project history over the life of the project in the form of a markdown file (relevant format for the web). It contains the following elements:

* Research questions

* Methodology

* Data sources

* Data cleaning & manipulations (with rationals)

* Earlier visualizations for reporting to colleagues


# Data

```{r, echo = FALSE, fig.cap="Was that version 37b'?", fig.align = "center"}
knitr::include_graphics(path = "./figures/data.png")
```


I usually subdivide the `data` folder into `raw` and `tidy`. I do not save data versions but rather the code performing the data cleaning and manipulation on the raw data. At the end of this code, I save the tidy data set in `tidy`. I can then load the data from this subfolder to save time if the cleaning code takes time to run.



# Coding practices

```{r, echo = FALSE, fig.cap="What is this f@#&!% code doing?", fig.align = "center"}
knitr::include_graphics(path = "./figures/messy_code.png")
```

Always remember Karl Broman's quote: **"Your closest collaborator is you, six months ago, but you don't respond to emails"**. 

Commenting your code and maintaining a project history may seem like a loss of time. My experience is that the time I "lose" is saved later on if I have to go back to the project: if I have to reuse part of a code or if I need to share it with a colleague. In my opinion, the time "lost" in the short term is more than saved over the long term.

As I already mentioned, I usually write one script per task 

* Cleaning

* EDA

* Modeling

* ...

I also add a short description at the top of each script, write clear commenting and define sections in the script for better visibility. 

```{r, echo = FALSE, fig.cap="One example", fig.align = "center"}
knitr::include_graphics(path = "./figures/coding.png")
```
   



# Sharing code and data


```{r, echo = FALSE, fig.cap="Version Control System (VCS)", out.width=400, out.height=300, fig.align = "center"}
knitr::include_graphics(path = "./figures/vcs.png")
```
 

Version control is a system that records changes to a file or set of files over time so that you can recall specific versions later. It also allows others to look at analyses you have performed and possibly reproduce them.

Personally, I use Github which is free and is frequently used by the research community. Having an account allows you at least to

* Share your code online

* Back-up every version of your code

* Collaborate with colleagues (historically it was a tool for software developpers)

It requires to use the command line (Git Bash) but you only need some commands to start and maintain a project on your own.


## Github in practice

1) Create an account on Github's [website](https://github.com/).

2) Create a repository for a project (set a repo name, decide if public or private) and keep the obtained page open.

3) Download [Git Bash](https://git-scm.com/downloads) on your computer

4) Open Git Bash and use the following commands (each run by pressing enter):

```{r, eval = FALSE}
# Print the present working directory where Git Bash is located
pwd 

# Use cd "repository path" to let Git Bash know where to locate the current directory.
# Locate it in the project you want to add to Github.  
cd "C:/Users/..../my_first_project"

# Initializes the folder as a local repo. Files in the folder will now be tracked.
git init	

# Gives you the status (tracked/untracked) of the different folders and files present.
git status

# Adding file(s).
git add "filename.extension"		
# Alternatively, the command "git add ." will add all folders and files present in the repo.

# Adds a brief message explaining what changes were made.
git commit -m "your brief message here"

# Defines that it is the main branch (easiest case)
git branch -M main

# Connects your local repository to the one you created on the Github server.
# This step is only required once, when initializing a repo.
# Note that the URL is shown at the top of the Github 
# webpage, just after creating your repository.
git remote add origin https://github.com/user_name/repo_name.git

# Finally, push the files and associated message from your laptop to 
# the Github server.
git push -u origin main

```


If you now go back to your repository on Github and refresh the page, you should see the file(s) you added and the message associated to the changes. 

The initialization is done. Let's now focus on how it works when progressing on the project. Assume that you go back to this project some days later. Further suppose that you work on a script called "cleaning_data.R". When you are satisfied with your work, open Git Bash and write the following commands:

```{r, eval = FALSE}
# Running the command "git status" will tell you that cleaning_data.R
# has been modified. However, this command is not needed for what follows.

# Adds the modifications performed on cleaning_data.R
git add "cleaning_data.R"

# Adds the message briefly describing what you changed in the script.
git commit -m "convert NA into 0"

# Pushes the files to the Github server
git push -u origin main
```

Your changes are now on the Github server. You only need to iterate these three commands each time you make progress on your project.

The explanation above is all you need to start having your projects on Github. Some importants notes: 

* Suppose you have subfolders in your local repository. In order to add all folders and files to Github, you can simply use the command "`git add .`". However, if you only want to add one file located in a subfolder, the file's name needs to contain the path: `git add "./subfolder_name/file_name.extension"`.

* If you made your repository public, colleagues will have the possibility to extract your repo on their laptop. This means more commands but it opens the door to collaboration. 


# Summary

I presented some advices on how to conduct a research project while making it reproducible. I did not talk about pre-prints, open access journals and sharing data but these are also critical elements for reproducibility. In practice, it is frequently not as easy as presented in this post. Conducting research is more of a circular process than a linear one. Nonetheless, keeping these elements in mind still allows to converge towards reproducibility in data-centric analyses. 
