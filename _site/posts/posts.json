[
  {
    "path": "posts/2022-02-10-demographic-indicators-of-belgium/",
    "title": "Demographic indicators of Belgium",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Benjamin Schlüter",
        "url": {}
      }
    ],
    "date": "2022-02-10",
    "categories": [],
    "contents": "\r\nPopulation evolution over time\r\nMedian age of Belgian\r\nPopulation pyramid on 3 time points\r\n+65 share variation across districts/commune?\r\nDependency ratio on the same time points\r\nFertility (age at first birth, ASFR, PASFR)\r\nSeasonality of death\r\nMale to Female ratio over age\r\nMortality ?\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-10T08:56:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-10-math-of-mortality/",
    "title": "Math of mortality",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Benjamin Schlüter",
        "url": {}
      }
    ],
    "date": "2022-02-10",
    "categories": [],
    "contents": "\r\nThe field of mortality can be analyzed (at minimal) with three complementary functions: hazard, survival and death probability density function.\r\nLet denote X: the age at death of an individual and assume that this random variable is \\(X\\geq 0\\) and continuous.\r\nSuriving beyond age x is expressed as\r\n\\[\r\n\\begin{align}\r\nS(x) & = Pr(X>x) \\\\\r\nS(x) & = 1 - F(x) \\\\\r\nS'(x) & = -f(x) \r\n\\end{align}\r\n\\]\r\n\\[S(x) = Pr(X > x) = -\\int^{\\infty}_xf(t)dt\\]\r\nLet’s now express the hazard function, also called the force of mortality:\r\n\\[\r\n\\begin{align}\r\nh(x) &= lim_{\\Delta x \\rightarrow 0} \\frac{Pr(x \\leq X < x + \\Delta x | X > x)}{\\Delta x} \\\\\r\n &= lim_{\\Delta x \\rightarrow 0} \\frac{Pr(X < x + \\Delta x) - Pr(X \\leq x)}{\\Delta x} \\cdot \\frac{1}{Pr(X>x)} \\\\\r\n &= \\frac{f(t)}{S(t)}\r\n\\end{align}\r\n\\]\r\nThus, the force of mortality can be expressed as\r\n\\[\r\n\\begin{align}\r\n\\boxed{h(x) = -\\frac{d}{dx}ln(S(x))}\r\n\\end{align}\r\n\\]\r\nand re-arranging that equation we expressed the survival probability at age t as\r\n\\[\\boxed{S(t) = e^{-\\int^t_0h(x)dx} = e^{-H(t)}}\\]\r\nor also\r\n\\[S(t+n) = S(t)e^{-\\int^{t+n}_{t}h(x)dx}\\]\r\nwhere \\(H(t)\\) is called the cumulative hazard.\r\nNote that when \\(h(x)\\) is constant,\r\n\\[S(t) = e^{-ht}\\]\r\nFrom earlier derivation of \\(h(x)\\) we can obtain a math expression for the death probability density function\r\n\\[\\boxed{f(x) = h(x)S(x)}\\]\r\nLet’s check these identities visually.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-10T08:32:55+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-10-ml-estimation-of-mortality-models-with-nn-r/",
    "title": "ML estimation of mortality models with NN-R",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Benjamin Schlüter",
        "url": {}
      }
    ],
    "date": "2022-02-10",
    "categories": [],
    "contents": "\r\nWhen studying demographic methods for mortality estimations, we encounter the issue of estimating mortality at old ages where data are sparse (fewer deaths and fewer survivors). In this context, D. M. Feehan (2018) advised to estimate mortality models using maximum likelihood for several reasons. One of the reason that is of interest for this post is that estimating parameters by maximizing a likelihood accounts for the data available at each age, giving less influence to older ages in parameter estimates. In what follows, we will look at the difference between parameters estimated in the context of a simple linear model and parameters estimated in the context of a Maximum Likelihood estimation. The MLE will be performed using the Newton-Raphson (N-R) maximization algorithm to estimate parameters for the Gompertz and Log-Quadratic models.\r\nWe will use the Belgian mortality age schedule in 2002 (deaths and exposures from Human Mortality Database) where old age mortality showed “unusual” low mortality rates, most likely due to sparse data at these ages. What we will do in the following is to try to model data points in the rectangle showed on the figure.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFitting mortality models by OLS\r\n\r\n\r\n\r\nOne solution sometimes performed (and that is not advisable as you will see) is to fit a linear model on the logarithm of the mortality rates. Gompertz and Log-Quadtric model would then be expressed respectively as follow:\r\n\\(\\begin{aligned}  ln(m_x) & \\sim Normal(\\alpha_1 + \\alpha_2x, \\sigma) \\\\  ln(m_x) & \\sim Normal(\\alpha_1 + \\alpha_2x + \\alpha_3x^2, \\sigma) \\end{aligned}\\)\r\nwhere \\(x \\in \\{80, 81, .., A\\}\\) is age from age 80 years old.\r\nPoisson Log Likelihood\r\nInstead we can derive the likelihood assuming deaths \\(D_x\\) follow a poisson distribution. We assume that deaths, \\(D_x\\), at each age \\(x \\in \\{80, 81, .., A\\}\\) have a Poisson distribution with expected value equal to the observed exposure \\(N_x\\) times the mortality rate:\r\n\\[D_x \\sim Poisson(N_x \\mu_x)\\] The sample likelihood can be expressed as\r\n\\[L(D_x | N_x, \\mu_x) = \\prod_{x=80}^G \\frac{(N_x \\mu_X)^{D_x}e^{-(N_x \\mu_x)}}{D_x!}\\]\r\nThus the sample log likelihood is\r\n\\[l(\\mu_x) = K + \\sum_{x=80}^G (D_xln(\\mu_x) - \\hat{D_x})\\]\r\nwhere \\(\\hat{D_x}=N_x \\mu_x\\) is the expected number of deaths predicted by the model, \\(K\\) is a constant not depending on \\(\\mu_x\\) and \\(G\\) corresponds to the number of age group considered.\r\nIn this post, we will consider two mortality models: Gompertz and Log-Quadratic. In what follows, we show the math for the Gompertz model. Mortality rates are commonly expressed as follow in the Gompertz model\r\n\\[\\mu_x = exp(\\alpha_1 + \\alpha_2x)\\] In matrix form we can rewrite that as\r\n\\[\\boldsymbol{\\lambda} = ln(\\boldsymbol{\\mu}) = \\boldsymbol{X\\alpha}\\]\r\nwhere \\(\\boldsymbol{X}\\) is a \\(G \\times 2\\) design matrix, \\(\\boldsymbol{\\alpha}\\) is a \\(2 \\times 1\\) vector and \\(ln(\\boldsymbol{\\mu})\\) is a \\(G \\times 1\\) vector of log mortality rates.\r\nMaximizing the Log Likelihood via Newton-Raphson iteration\r\nWe search \\(\\boldsymbol{\\alpha}\\) to maximize \\(\\boldsymbol{l(\\alpha)}\\). For Newton-Raphson algorithm to do that we need both first and second derivatives of \\(\\boldsymbol{l(\\alpha)}\\)\r\n\\[\\frac{\\partial \\boldsymbol{l(\\alpha)}}{ \\partial \\boldsymbol{\\alpha}} = \\sum_{x=80}^G(D_x-\\hat{D_x})\\boldsymbol{x_x} = \\boldsymbol{X'(D-\\hat{D})} = 0\\]\r\nsince \\(\\frac{ln(\\mu_x)}{\\partial \\boldsymbol{\\alpha}} = \\boldsymbol{x_x}\\), \\(\\frac{\\partial \\mu_x}{\\partial \\boldsymbol{\\alpha}} = \\mu_x \\boldsymbol{x_x}\\) and \\(\\frac{\\partial \\hat{D_x}}{\\partial \\boldsymbol{\\alpha}} = N_x\\mu_x \\boldsymbol{x_x} = \\hat{D_x}\\boldsymbol{x_x}\\).\r\nThe second derivatives are then\r\n\\[\\frac{\\partial^2 \\boldsymbol{l(\\alpha)}}{ \\partial \\boldsymbol{\\alpha}\\boldsymbol{\\alpha'}} = \\sum_{x=80}^G(-\\frac{\\partial \\hat{D_x}}{\\partial \\boldsymbol{\\alpha'}}\\boldsymbol{x_x}) = \\sum_{x=80}^G(\\boldsymbol{-x_x' \\hat{D_x} x_x}) = -\\boldsymbol{X'}diag(\\hat{\\boldsymbol{D}})\\boldsymbol{X}\\] The Newton-Raphson algorithm for solving \\(\\frac{\\partial \\boldsymbol{l(\\alpha)}}{ \\partial \\boldsymbol{\\alpha}}=0\\) is\r\n\\[\\boldsymbol{\\alpha_{i+1}} = \\boldsymbol{\\alpha_i}-[\\frac{\\partial^2 \\boldsymbol{l(\\alpha)}}{ \\partial \\boldsymbol{\\alpha}\\boldsymbol{\\alpha'}}]^{-1}[\\frac{\\partial \\boldsymbol{l(\\alpha)}}{ \\partial \\boldsymbol{\\alpha}}]\\] which in our case is\r\n\\[\\boldsymbol{\\alpha_{i+1}} = \\boldsymbol{\\alpha_i}+[\\boldsymbol{X'}diag(\\hat{\\boldsymbol{D}})\\boldsymbol{X}]^{-1}[\\boldsymbol{X'(D-\\hat{D})}]\\]\r\nand is shown in the R-code below\r\n\r\n\r\n# Design matrix\r\nX = matrix(c(rep(1, dim(df)[1]), df$Age),\r\n           ncol = 2)\r\n# vector of deaths and exposure\r\nD = df$D\r\nN = df$N\r\n# Expected deaths according to alpha\r\nDhat = function(alpha) {\r\n  lambda.hat = X %*% alpha\r\n  return( as.numeric( N * exp(lambda.hat)))\r\n}\r\n# Newton-Raphson algorithm\r\nnext_alpha = function(alpha) {\r\n  dhat = Dhat(alpha)\r\n  M = solve ( t(X) %*% diag(dhat) %*% X)\r\n  v = t(X) %*% (D - dhat)\r\n  return( alpha + M %*% v)\r\n}\r\n\r\na = matrix(0, 2, 15)\r\nfor (i in 2:ncol(a)) { a[,i] = next_alpha(a[,i-1])}\r\n\r\n\r\n\r\nAlpha values over N-R iterations. Convergence before tenth iteration.\r\n\r\n\r\n\r\nGompertz fit of old age mortality. Regression gives more weights to rates at oldest ages.\r\n\r\n\r\n\r\n\r\n\r\n\r\nAlgorithm only need a third column in design matrix and an additional line in a. Alpha values over N-R iterations. Convergence before tenth iteration.\r\n\r\n\r\n\r\nGompertz and Log-Quadratic fits. Regression outputs more sensitive to outlying value.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-10T08:48:29+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-10-temporal-smoother-with-bayes/",
    "title": "Temporal smoother with Bayes",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Benjamin Schlüter",
        "url": {}
      }
    ],
    "date": "2022-02-10",
    "categories": [],
    "contents": "\r\nSee slides 13, 30-32 from part 2 Wakefield to defines the topics of this post.\r\nSample prevalence in a area (small- medium size: impact on variation of proportion)\r\nBAYESIAN formula good for smoothing (prior)\r\n\r\n\r\n\r\n\r\n\r\n\r\nProportion of individuals with a characteristic over time.\r\n\r\n\r\n\r\nEstimating RW(1) model\r\n\r\n\r\n\r\n\r\n# STAN code\r\ndata {\r\n  int<lower=0> N; // number of lines\r\n  int<lower=0> T_pts; // number of time points\r\n  \r\n  int<lower=0, upper=1> y[N]; // success/failure\r\n  int<lower=1, upper=81> t[N]; // time point of success/failure\r\n}\r\nparameters {\r\n  real alpha;\r\n  vector[T_pts] phi;\r\n  real<lower=0> sigma;\r\n}\r\ntransformed parameters {\r\n  vector[T_pts] eta;\r\n  vector[T_pts] p_hat;\r\n\r\n  eta = alpha + phi;\r\n  \r\n  for (i in 1:T_pts){\r\n      p_hat[i] = 1/(1+exp(-eta[i]));\r\n  }\r\n}\r\nmodel {\r\n  \r\n  alpha ~ normal(0, 10);\r\n  phi[1] ~ normal(0, 10);\r\n  phi[2:T_pts] ~ normal(phi[1:(T_pts-1)], sigma);\r\n  sigma ~ normal(0, 10);\r\n  \r\n  for (i in 1:N) {\r\n      y[i] ~ bernoulli_logit(eta[ t[i] ]);\r\n  }\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-02-10-temporal-smoother-with-bayes/temporal-smoother-with-bayes_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2022-02-11T09:19:48+01:00",
    "input_file": {}
  }
]
